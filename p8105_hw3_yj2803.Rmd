---
title: "Homework 3"
author: "Yuki Joyama"
date: "2023-10-05"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE, message = FALSE)

library(tidyverse)
```

# Problem 1

**Data import setup**
```{r}
library(p8105.datasets)
data("instacart") # call instacart data from the library 
```

The instacart data has `r nrow(instacart)` rows and `r ncol(instacart)` columns. Some key variables include order_id, product_id, user_id, product_name, etc.

**Examples of observations in instacart dataset**
```{r}
head(instacart, n = 8) |> 
  knitr::kable(digits = 1) # include table in the md file
```

The above example shows detailed information about `order_id` = 1. As we can see from the table, `order_id` is tied to specific IDs which identify product, user, aisle and department. From `product_name`, we can tell what the user got for this order. `order_number` = 4 means that this was the 4th order from this customer. `order_dow`, `order_hour_of_day`, and `days_since_prior` tell us that this order was placed on the 4th week, between 10 am to 11 am, and 9 days since the last order. `reordered` is recorded as 1 if the product has been ordered by this user in the past, and 0 otherwise. 

```{r}
# summarize aisle data
df_aisles <- instacart |> 
  group_by(aisle_id, aisle) |> 
  summarise(count = n())  # count how many times aisle_id were recorded in the dataset for each id (= the number of items ordered from each aisle)

max_aisle <- max(pull(df_aisles, count)) # check maximum count of aisles

df_aisles_max <- df_aisles |> 
  filter(count == max_aisle) # filter by the maximum count of aisles
```

`r max(pull(instacart, aisle_id))` aisles are in this dataset, and **`r pull(df_aisles_max, aisle)`** are the most items (in total `r max_aisle` items) ordered from.

The following plot shows the number of items ordered in each aisle, limiting this to aisles with more than 10000 items ordered.
```{r}
# make a plot (the number of items ordered in each aisle)
df_aisles |> 
  filter(count > 10000) |> # just show aisles with more than 10000 items 
  ggplot(aes(x = reorder(aisle, count), y = count)) + 
  geom_bar(stat = "identity") +
  theme(axis.text.x = element_text(angle = 90)) +
  labs(
    title = "Items by aisle",
    x = "Aisle",
    y = "Item count",
    caption = "Only showing aisles with more than 10000 items ordered; sorted in an ascending order"
  )
```

**Popular items in "baking ingredients"**
```{r}
# table showing the three most popular items in "baking ingredients"
df_baking_ingredients <- instacart |> 
  filter(aisle == c("baking ingredients")) |> # filter by aisle
  group_by(product_name) |> 
  summarise(count = n()) |> # add count for each item
  arrange(desc(count)) |> # arrange in descending order
  head(n = 3) # only show the first three items
  
df_baking_ingredients |> 
  knitr::kable(digits = 1) # show table in md file 
```
The three most popular items in "baking ingredients" are `r pull(df_baking_ingredients, product_name)`.

**Popular items in "dog food care"**
```{r}
# table showing the three most popular items in "dog food care"
df_dog_food_care <- instacart |> 
  filter(aisle == c("dog food care")) |> # filter by aisle
  group_by(product_name) |> 
  summarise(count = n()) |> # add count for each item
  arrange(desc(count)) |> # arrange in descending order
  head(n = 3) # only show the first three items
  
df_dog_food_care |> 
  knitr::kable(digits = 1) # show table in md file 
```
The three most popular items in "dog food care" are `r pull(df_dog_food_care, product_name)`.

**Popular items in "packaged vegetables fruits"**
```{r}
# table showing the three most popular items in "packaged vegetables fruits"
df_packaged_vegetables_fruits <- instacart |> 
  filter(aisle == c("packaged vegetables fruits")) |> # filter by aisle
  group_by(product_name) |> 
  summarise(count = n()) |> # add count for each item
  arrange(desc(count)) |> # arrange in descending order
  head(n = 3) # only show the first three items
  
df_packaged_vegetables_fruits |> 
  knitr::kable(digits = 1) # show table in md file 
```
The three most popular items in "packaged vegetables fruits" are `r pull(df_packaged_vegetables_fruits, product_name)`.

The table below provides the mean order time for Pink Lady Apples and Coffee Ice Cream on each day of the week:

**Pink Lady Apples and Coffee Ice Cream table**
```{r warning = FALSE}
# Pink Lady Apples and Coffee Ice Cream table
instacart |> 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) |> # filter by product name
  group_by(product_name, order_dow) |> 
  summarise("mean_hour" = mean(order_hour_of_day)) |> # show the mean hour of the day on each day of the week
  pivot_wider(
    names_from = order_dow, 
    values_from = mean_hour
  ) |> 
  knitr::kable(digits = 1) # show table in md file 
```

# Problem 2

**Data import setup**
```{r}
library(p8105.datasets)
data("brfss_smart2010") # call BRFSS data from the library 
```

**Data cleaning**
```{r warning = F}
df_brfss_cleaned <- brfss_smart2010 |> 
  janitor::clean_names() |> 
  filter(topic == "Overall Health" & response %in% c("Excellent", "Very good", "Good", "Fair", "Poor")) |>  # focus on Overall Health; only include responses from "Excellent" to "Poor"
  mutate(
    response = factor(response, levels = c("Poor", "Fair", "Good", "Very good", "Excellent")) # change response as factor taking levels ordered from “Poor” to “Excellent”
  )
```


```{r}
# check 2002
df_brfss_2002 <- df_brfss_cleaned |> 
  filter(year == 2002) |>  # filter by year 
  group_by(locationabbr) |> # group by states
  summarise(count = n() / 5) |> # count number of observations in each state
  filter(count >= 7) # show states which have >= 7 locations

# check 2010
df_brfss_2010 <- df_brfss_cleaned |> 
  filter(year == 2010) |>  # filter by year 
  group_by(locationabbr) |> # group by states
  summarise(count = n() / 5) |> # count number of observations in each state
  filter(count >= 7) # show states which have >= 7 locations
```

7 or more locations were observed in `r pull(df_brfss_2002, locationabbr)` in 2002; `r pull(df_brfss_2010, locationabbr)` in 2010.

```{r fig.width = 12, fig.height = 6}
# create a dataset that is limited to "Excellent" responses
df_brfss_excellent <- df_brfss_cleaned |> 
  filter(response == "Excellent") |> # filter by response "Excellent"
  select(year, locationabbr, data_value) |> # only include necessary variables in the dataset
  group_by(locationabbr, year) |> 
  drop_na() |> # drop the missing values so that we can calculate mean value
  summarise(value_mean = mean(data_value)) # calculate mean data_value across locations within a state

# create a spaghetti plot with x being year, y being the value_mean
df_brfss_excellent |> 
  rename("state" = locationabbr) |> # renamed column for plot output
  ggplot(aes(x = year, y = value_mean, group = state, color = state)) + 
  geom_line() + # spaghetti plot
  theme(legend.text = element_text(size = 6)) + # changed legend text size
  guides(color = guide_legend(ncol = 3)) + # changed the number of legend columns
  labs(
    title = "The average value over time within a state",
    x = "Year",
    y = "The average value",
    caption = "Only showing data with Excellent response"
  ) 
```
The graph indicates that the average value among people who responded Excellent in each state is slightly decreasing over the year.

```{r fig.width = 12, fig.height = 6}
library(patchwork) # to create a two-panel plot

# prepare a dataset for plot
df_ny_2006 <- df_brfss_cleaned |> 
  filter(locationabbr == "NY" & year == 2006)  # only include 2006 data in NY
  
df_ny_2010 <- df_brfss_cleaned |> 
  filter(locationabbr == "NY" & year == 2010)  # only include 2006 data in NY
  
# plot for 2006
p_ny_2006 = df_ny_2006 |> 
  ggplot(aes(x = response, y = data_value)) +
  geom_boxplot() +
  theme(legend.position = "bottom", axis.text.x = element_text(angle = 90)) + # change the legend location
  labs(
    title = "2006",
    x = "responses",
    y = "data value"
  )

# plot for 2010
p_ny_2010 = df_ny_2010 |> 
  ggplot(aes(x = response, y = data_value)) +
  geom_boxplot() +
  theme(legend.position = "bottom", axis.text.x = element_text(angle = 90)) + # change the legend location
  labs(
    title = "2010",
    x = "responses",
    y = "data value",
    caption = "* data values in this plot are obtained from NY State in 2006 and 2010"
  ) 

p_ny_2006 + p_ny_2010 # put two plots side by side
```
The boxplots shows the data values by responses (2006 vs 2010). From this graph, we can tell that those who responded "Very good" have the highest data values, and those who responded "Poor" have the lowest data values in both 2006 and 2010.

# Problem 3

**Data import and cleaning**
```{r}
# import and clean demographic data
df_covar = read_csv("./data/nhanes_covar.csv", skip = 4) |> # import csv file
  janitor::clean_names() |> 
  mutate(
    sex = case_match(  
      sex,
      1 ~ "male",
      2 ~ "female"
    ),  # rewrite sex variables
    education = case_match(
      education,
      1 ~ "less than high school",
      2 ~ "high school equivalent",
      3 ~ "more than high schol"
    ), # rewrite education variables
    education = factor(education, levels = c("less than high school", "high school equivalent", "more than high schol")) 
  ) |> # change education to factor variable
  drop_na() |> # exclude those with missing demographic data
  filter(age >= 21)

# import and clean accelerometer data
df_accel = read_csv("./data/nhanes_accel.csv") |> # import csv file
  janitor::clean_names() |> 
  pivot_longer( # change the dataset from wide to long
    min1:min1440,
    names_to = "min",
    values_to = "mims_values",
    names_transform = list(min = ~as.numeric(gsub("min", "", .))) # just show numbers in the min column
  )

# merge the two datasets
df_mims_cleaned =  
  left_join(df_covar, df_accel, by = "seqn")
```

**The number of men and women in each educaiton category**
```{r}
df_mims_cleaned |> 
  group_by(sex, education) |> # group by sex and education
  summarise(count = n_distinct(seqn)) |> 
  pivot_wider( # change the table from long to wide
    names_from = education, 
    values_from = count
  ) |> 
  knitr::kable(digits = 1)
```
The table shows the number of men and women in each education category. The number of people who received more than high school education was the largest in both sex.

**The age distribution**
```{r warning = F, fig.width = 12, fig.height = 6}
# boxplot of age distribution
df_mims_cleaned |> 
  ggplot(aes(x = sex, y = age)) +
  geom_boxplot(aes(fill = sex), alpha = .5) + 
  labs(
    title = "Boxplot of age distribution by sex and education level"
  ) +
  facet_grid(~ education) +
  theme(legend.position = "bottom") +
  viridis::scale_fill_viridis(discrete = TRUE)
```
The boxplot shows that among male, the lower the education level is, the older the age is. Among female, those who received "high school equivalent" education appears to have the highest median age.

**Total activity**
```{r warning = F, fig.width = 12, fig.height = 6}
df_mims_cleaned |> 
  group_by(seqn, age, sex, education) |> 
  summarise(
    total_values = sum(mims_values) 
  ) |> # added a column that sums up mims_values for each individual
  ggplot(aes(x = age, y = total_values, color = sex)) +
  geom_point(alpha = .5) +
  geom_smooth(se = F) +
  facet_grid(~ education) +
  labs(
    title = "Total activity over the day",
    y = "total activity value"
  ) +
  theme(legend.position = "bottom") +
  viridis::scale_color_viridis(
    discrete = TRUE
  )
```
The graph shows total activity value against age in each sex and education level. In "less than high school" education level, young people in their 20-40s, especially women, are generally more active. In "high school equivalent" education level, both men and women in their 30-50s are the most active. In "more than high school" education level, older people (60s~) maintain a relatively high level of total activity, with a less steep decline than other education levels.

**24-hour activity time courses**
```{r warning = F, fig.width = 12, fig.height = 6}
df_mims_cleaned |> 
  group_by(min, sex, education) |> 
  summarise(avg_mims_values = mean(mims_values)) |> 
  ggplot(aes(x = min, y = avg_mims_values, color = sex)) +
  geom_point(alpha = .05) +
  geom_smooth(se = F) +
  facet_grid(~ education) +
  labs(
    title = "24-hour activity activity time courses of the day",
    y = "mean activity value"
  ) +
  theme(legend.position = "bottom") +
  viridis::scale_color_viridis(
    discrete = TRUE
  )
```
The plots indicate that in "less than high school" education level, the maximum values of the mean activity values are the highest among all. In "more than high school" education level, we can see that people maintain relatively high activity level from morning to evening whereas "less than high school" education level group shows a slight decrease in activity level in the evening. At all education level, females generally have higher activity levels during the day than males, and lower levels than males at night. 
